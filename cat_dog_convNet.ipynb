{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2b1e7a-bb09-40d4-81b5-7e2f67ac44c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1638/1638 [==============================] - 231s 140ms/step - loss: 0.5427 - accuracy: 0.7214 - val_loss: 0.4610 - val_accuracy: 0.7862\n",
      "Epoch 2/20\n",
      "1638/1638 [==============================] - 228s 139ms/step - loss: 0.4376 - accuracy: 0.7979 - val_loss: 0.4408 - val_accuracy: 0.7910\n",
      "Epoch 3/20\n",
      "1638/1638 [==============================] - 227s 138ms/step - loss: 0.3802 - accuracy: 0.8297 - val_loss: 0.3584 - val_accuracy: 0.8360\n",
      "Epoch 4/20\n",
      "1638/1638 [==============================] - 227s 139ms/step - loss: 0.3364 - accuracy: 0.8520 - val_loss: 0.3024 - val_accuracy: 0.8744\n",
      "Epoch 5/20\n",
      "1638/1638 [==============================] - 225s 137ms/step - loss: 0.2993 - accuracy: 0.8713 - val_loss: 0.2935 - val_accuracy: 0.8739\n",
      "Epoch 6/20\n",
      "1638/1638 [==============================] - 226s 138ms/step - loss: 0.2677 - accuracy: 0.8865 - val_loss: 0.2309 - val_accuracy: 0.9046\n",
      "Epoch 7/20\n",
      "1638/1638 [==============================] - 231s 141ms/step - loss: 0.2369 - accuracy: 0.9013 - val_loss: 0.1995 - val_accuracy: 0.9238\n",
      "Epoch 8/20\n",
      "1638/1638 [==============================] - 225s 138ms/step - loss: 0.2109 - accuracy: 0.9138 - val_loss: 0.1847 - val_accuracy: 0.9259\n",
      "Epoch 9/20\n",
      "1638/1638 [==============================] - 230s 140ms/step - loss: 0.1901 - accuracy: 0.9231 - val_loss: 0.1691 - val_accuracy: 0.9339\n",
      "Epoch 10/20\n",
      "1638/1638 [==============================] - 231s 141ms/step - loss: 0.1662 - accuracy: 0.9326 - val_loss: 0.1516 - val_accuracy: 0.9417\n",
      "Epoch 11/20\n",
      "1638/1638 [==============================] - 229s 140ms/step - loss: 0.1490 - accuracy: 0.9409 - val_loss: 0.1227 - val_accuracy: 0.9558\n",
      "Epoch 12/20\n",
      "1638/1638 [==============================] - 231s 141ms/step - loss: 0.1310 - accuracy: 0.9495 - val_loss: 0.1190 - val_accuracy: 0.9546\n",
      "Epoch 13/20\n",
      "1638/1638 [==============================] - 227s 139ms/step - loss: 0.1153 - accuracy: 0.9567 - val_loss: 0.1047 - val_accuracy: 0.9618\n",
      "Epoch 14/20\n",
      "1638/1638 [==============================] - 224s 137ms/step - loss: 0.1012 - accuracy: 0.9628 - val_loss: 0.0903 - val_accuracy: 0.9690\n",
      "Epoch 15/20\n",
      "1638/1638 [==============================] - 227s 138ms/step - loss: 0.0886 - accuracy: 0.9680 - val_loss: 0.0712 - val_accuracy: 0.9768\n",
      "Epoch 16/20\n",
      "1638/1638 [==============================] - 226s 138ms/step - loss: 0.0775 - accuracy: 0.9723 - val_loss: 0.0632 - val_accuracy: 0.9798\n",
      "Epoch 17/20\n",
      "1638/1638 [==============================] - 225s 137ms/step - loss: 0.0673 - accuracy: 0.9761 - val_loss: 0.0614 - val_accuracy: 0.9800\n",
      "Epoch 18/20\n",
      "1638/1638 [==============================] - 225s 138ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 0.0405 - val_accuracy: 0.9892\n",
      "Epoch 19/20\n",
      "1638/1638 [==============================] - 226s 138ms/step - loss: 0.0540 - accuracy: 0.9812 - val_loss: 0.0371 - val_accuracy: 0.9913\n",
      "Epoch 20/20\n",
      "1638/1638 [==============================] - 226s 138ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.0320 - val_accuracy: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ce92198d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf  # Import TensorFlow library for deep learning\n",
    "from tensorflow.keras.models import Sequential  # Sequential model for building neural networks layer by layer\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D  # Import necessary layers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle  # Import the pickle library for loading data\n",
    "import numpy as np  # Import NumPy for numerical operations\n",
    "import time  # Import time for timestamp generation\n",
    "import os  # Import os for handling file paths\n",
    "\n",
    "# Limit CPU usage\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"        # Set the number of OpenMP threads\n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"2\" # Number of threads used for intra-op parallelism\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"1\" # Number of threads used for inter-op parallelism\n",
    "\n",
    "# Create a unique name for the TensorBoard logs using the current timestamp\n",
    "NAME = \"Cats-vs-dog-cnn-64x2-without-dense-{}\".format(int(time.time()))\n",
    "\n",
    "# Initialize TensorBoard callback with the correct log directory\n",
    "log_dir = os.path.join(\"logs\", NAME)\n",
    "tensorboard = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Load preprocessed image data and labels from pickle files\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))  # Load feature data (images)\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))  # Load labels (categories)\n",
    "\n",
    "# Normalize the pixel values of images to a range of 0 to 1\n",
    "X = X / 255.0  \n",
    "\n",
    "# Convert y to a NumPy array to ensure it's in the correct format for training\n",
    "y = np.array(y)\n",
    "\n",
    "# Verify that the number of samples in X matches the number of labels in y\n",
    "assert X.shape[0] == y.shape[0], \"Number of samples in X and y must match.\"\n",
    "\n",
    "# Configure TensorFlow to use GPU appropriately\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers and pooling layers\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output from the convolutional layers to feed into the dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected (dense) layer\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "# Output layer for binary classification\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "# Compile the model with specified parameters\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the training data and TensorBoard callback for logging\n",
    "model.fit(X, y, batch_size=32, epochs=20, validation_split=0.3, callbacks=[tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Clean ML)",
   "language": "python",
   "name": "cleanmlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
